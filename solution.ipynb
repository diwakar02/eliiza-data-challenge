{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('base': conda)",
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "3145b20aec8b7386d540c1ad7ab38171f6e113f0583c5c2a6610d5d84f997659"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from shapely.geometry import mapping\n",
    "from polygon_utils import may_intersect, intersection_area_bool\n",
    "from utils import to_poly, cleaned_polygon\n",
    "from past.builtins import xrange\n",
    "from functools import reduce\n",
    "\n",
    "# NOTE: please change the path to current setup in your system\n",
    "# windows\n",
    "if sys.platform.startswith('win'):\n",
    "    # location where all the programs will be stored this project location\n",
    "    os.chdir(r\"C:\\Users\\Diwakar Sharma\\Pictures\\PySparkV2\")\n",
    "    \n",
    "    # path of spark installation\n",
    "    os.environ['SPARK_HOME'] = r\"C:\\spark\"\n",
    "\n",
    "# do same  if there are other platforms\n",
    "os.curdir\n",
    "\n",
    "# Create variable for root path\n",
    "SPARK_HOME = os.environ['SPARK_HOME']\n",
    "os.environ['PYSPARK_PYTHON'] = r\"C:\\Users\\Diwakar Sharma\\Pictures\\anaconda3\\python.exe\"\n",
    "\n",
    "# Add following paths\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME, \"python\"))\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME, \"python\", \"lib\"))\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME, \"python\", \"lib\", \"pyspark.zip\"))\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME, \"python\", \"lib\", \"py4j-0.10.7-src.zip\"))\n",
    "\n",
    "# Initialize spark session and spark context\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import Row\n",
    "from functools import reduce\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import BooleanType\n",
    "\n",
    "# create Spark Session\n",
    "spSession = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .appName(\"Pyspark Tuts\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.cores.max\", \"4\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"8g\") \\\n",
    "    .config(\"spark.sql.broadcastTimeout\", 3600) \\\n",
    "    .config(\"spark.network.timeout\", 10000000) \\\n",
    "    .config(\"spark.executor.heartbeatInterval\", 10000000) \\\n",
    "    .config(\"spark.sql.crossJoin.enabled\", \"true\") \\\n",
    "    .config(\"spark.worker.timeout\", 3600) \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"file:///C:/temp/spark-warehouse\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# get the spark context from Spark Session\n",
    "sparkContext = spSession.sparkContext\n",
    "# -*- coding: utf-8 -*-\n",
    "spSession.sparkContext.setLogLevel('INFO')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "242\n",
      "+----------------+--------------------+\n",
      "|      ForestArea|              Coords|\n",
      "+----------------+--------------------+\n",
      "|3.98043559067884|[[144.94191893846...|\n",
      "|9.17814705681699|[[144.94190895719...|\n",
      "|  3.007072111269|[[144.94187567637...|\n",
      "|3.86014890925862|[[144.94190080796...|\n",
      "|4.14718749660807|[[144.94188538484...|\n",
      "|1.46492895511503|[[144.97152597558...|\n",
      "|3.69308797904325|[[144.94186984499...|\n",
      "|3.75804691422453|[[144.94184858513...|\n",
      "|5.49937282149683|[[144.94125470898...|\n",
      "|5.70700410008907|[[144.94125593388...|\n",
      "+----------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "########################################\n",
    "# udf to map suburb to forest area\n",
    "########################################\n",
    "may_intersect_udf = F.udf(lambda x, y: may_intersect(x, y), BooleanType())\n",
    "\n",
    "########################################\n",
    "# load urbanForest datasets\n",
    "# for testing purpose only a subset is  \n",
    "# loaded due to computing infrastructure\n",
    "########################################\n",
    "urban_forest_rdd_part_zero = sparkContext.textFile(\"file:///C:/Users/Diwakar Sharma/Pictures/PySparkV2/melb_urban_forest_2016.txt/test1\").repartition(5)\n",
    "print(urban_forest_rdd_part_zero.count())\n",
    "urban_forest_data_zero = urban_forest_rdd_part_zero.map(lambda l: l.split(\"\\\"\"))\n",
    "urban_forest_map_zero = urban_forest_data_zero.map(lambda x: ((x[1], x[3])))\n",
    "urban_forest_map_zero = urban_forest_map_zero.map(lambda x: (x[0], \n",
    "                                                  cleaned_polygon(x[1])))\n",
    "urban_forest_map_zero = urban_forest_map_zero.map(lambda x: (float(x[0]), \n",
    "                                                  to_poly(x[1])))\n",
    "urban_forest_cleaned_zero = urban_forest_map_zero.toDF(['ForestArea', 'Coords'])\n",
    "\n",
    "urban_forest_cleaned_zero.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------------+------------------+\n|         Suburb|         TotalArea|\n+---------------+------------------+\n| Brunswick West| 3.179500000000001|\n|South Melbourne|            2.4948|\n|      Brunswick| 5.142499999999999|\n|     Ascot Vale|            3.8361|\n|  St Kilda East|2.4135000000000004|\n+---------------+------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# read json for inner city as DataFrame\n",
    "########################################\n",
    "inner_city_df = spSession.read.json(\"file:///C:/Users/Diwakar Sharma/Pictures/PySparkV2/melb_inner_2016.json\")\n",
    "drop_cols = [\"gcc_code16\", \"gcc_name16\", \"sa1_7dig16\", \"sa1_main16\", \n",
    "             \"sa2_5dig16\", \"sa2_main16\", \"gcc_code16\", \"gcc_name16\",\n",
    "             \"sa1_7dig16\", \"sa1_main16\", \"sa2_5dig16\", \"sa2_main16\",\n",
    "             \"sa3_code16\", \"sa3_name16\", \"sa4_code16\", \"sa4_name16\",\n",
    "             \"ste_code16\", \"ste_name16\", \"type\"]\n",
    "inner_city_df = inner_city_df.drop(*drop_cols)\n",
    "oldColumns = inner_city_df.schema.names\n",
    "newColumns = [\"Area\", \"geometry\", \"Suburb\"]\n",
    "cleaned_city_df = reduce(lambda inner_city_df, idx: inner_city_df.\n",
    "                         withColumnRenamed(oldColumns[idx], newColumns[idx]),\n",
    "                         xrange(len(oldColumns)), inner_city_df)\n",
    "cleaned_city_df = cleaned_city_df.select(\"Area\", \"geometry.coordinates\", \"Suburb\")\n",
    "melbourne_stats_df = cleaned_city_df.rdd.map(lambda x: \n",
    "                            (float(x[0]), to_poly(x[1]), x[2])).\\\n",
    "                             toDF([\"Area\", \"Coordinates\", \"Suburb\"])\n",
    "\n",
    "# find total area by suburb\n",
    "total_area_df = melbourne_stats_df.groupBy(\"Suburb\").agg({\"Area\": \"sum\"}).\\\n",
    "                withColumnRenamed(\"sum(Area)\", \"TotalArea\")\n",
    "\n",
    "total_area_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+------------------+\n|              Suburb|        ForestArea|\n+--------------------+------------------+\n|           Parkville| 5525.531878288416|\n|Flemington Raceco...|161.57590240909337|\n|           Docklands| 4713.978738002249|\n|Carlton North - P...|3039.1032570743387|\n|   Kensington (Vic.)|223.64138858032229|\n+--------------------+------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# cross join to get suburb mappings with ForestArea/TreeCanopy\n",
    "\n",
    "joined_urban_forest_df = urban_forest_cleaned_zero.crossJoin(melbourne_stats_df).where                              (may_intersect_udf(urban_forest_cleaned_zero.Coords,                                                          melbourne_stats_df.Coordinates))\n",
    "joined_urban_forest_df = joined_urban_forest_df.distinct().groupBy(\"Suburb\").agg(                                    {\"ForestArea\": \"sum\"}).withColumnRenamed(\n",
    "                            \"sum(ForestArea)\", \"ForestArea\")\n",
    "joined_urban_forest_df = joined_urban_forest_df.repartition(\"Suburb\")\n",
    "joined_urban_forest_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Intersection Area By Surbu\n",
      "+---------------+-------------------+\n",
      "|         Suburb|   IntersectionArea|\n",
      "+---------------+-------------------+\n",
      "| Brunswick West|0.40106951704206234|\n",
      "|South Melbourne| 0.3150696804359202|\n",
      "|      Brunswick|  0.648886622257908|\n",
      "|     Ascot Vale|0.48410477340804864|\n",
      "|  St Kilda East|0.30491464608960345|\n",
      "+---------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "polygon_list_df = melbourne_stats_df.select(\"Coordinates\")\n",
    "\n",
    "#self join\n",
    "joined_cross_geometry = melbourne_stats_df.crossJoin(polygon_list_df).where(\n",
    "                        intersection_udf(melbourne_stats_df.Coordinates,                                                polygon_list_df.Coordinates))\n",
    "\n",
    "joined_cross_geometry = joined_cross_geometry.withColumn(\"IArea\", lit(0)).\\\n",
    "                         repartition(\"Suburb\")\n",
    "joined_intersection = joined_cross_geometry.rdd.map(lambda x: (x.Suburb,\n",
    "                      x.IArea + intersection_area(x.Coordinates, x.Coordinates)\n",
    "                    )).toDF([\"Suburb\", \"IArea\"])\n",
    "intersection_area_df = joined_intersection.groupBy(\"Suburb\").agg({\"IArea\": \"sum\"})                                .withColumnRenamed(\"sum(IArea)\", \"IntersectionArea\")\n",
    "print(\"Intersection Area By Surbu\")\n",
    "intersection_area_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate actual area from intersection area\n",
    "actual_area_df = total_area_df.join(intersection_area_df, [\"Suburb\"])\n",
    "actual_area_df = actual_area_df.rdd.map(lambda x: (x.Suburb, (x.TotalArea - x.IntersectionArea))).toDF([\"Suburb\", \"ActualArea\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10\n",
      "+--------------------+------------------+------------------+\n",
      "|              Suburb|        ActualArea|        ForestArea|\n",
      "+--------------------+------------------+------------------+\n",
      "|           Parkville|3.5381872704130544| 5525.531878288416|\n",
      "|Flemington Raceco...|1.4935617358779143|161.57590240909337|\n",
      "|           Docklands|2.1354409067835927| 4713.978738002249|\n",
      "|Carlton North - P...|2.0133882063585213|3039.1032570743387|\n",
      "|   Kensington (Vic.)|1.8759950691214007|223.64138858032229|\n",
      "+--------------------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# join urban forest DF having Suburb and ForestArea to melbourne stats having Actual Area and Suburb\n",
    "forest_area_by_suburb_joined_df = actual_area_df.join(joined_urban_forest_df, [\"Suburb\"])\n",
    "print(forest_area_by_suburb_joined_df.count())\n",
    "forest_area_by_suburb_joined_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_area_by_suburb_joined_df = forest_area_by_suburb_joined_df.groupBy(\n",
    "                                    \"Suburb\").sum(\"ForestArea\", \"ActualArea\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_area_by_suburb_joined_df = forest_area_by_suburb_joined_df.withColumnRenamed(\"sum(ForestArea)\", \"ForestArea\").withColumnRenamed(\"sum(ActualArea)\", \"ActualArea\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Suburb', 'ForestArea', 'ActualArea']"
      ]
     },
     "metadata": {},
     "execution_count": 152
    }
   ],
   "source": [
    "forest_area_by_suburb_joined_df.schema.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find greenery ratio by Suburb\n",
    "greenest_suburb = forest_area_by_suburb_joined_df.rdd.map(lambda x: (x.Suburb, \n",
    "                     (x.ForestArea/x.ActualArea)*0.0001)).\\\n",
    "                     toDF([\"Suburb\", \"GreenRatio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Row(Suburb='Docklands', GreenRatio=0.22074966921479733)"
      ]
     },
     "metadata": {},
     "execution_count": 154
    }
   ],
   "source": [
    "# print greenest Suburb\n",
    "greenest_suburb.orderBy(F.col(\"GreenRatio\").desc()).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}